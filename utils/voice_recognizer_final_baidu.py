# utils/voice_recognizer_final_baidu.pyä¸»è¯­éŸ³è¯†åˆ«å™¨
import streamlit as st
import os
import time
from datetime import datetime

# å¯¼å…¥ç™¾åº¦è¯­éŸ³
try:
    try:
        from utils.baidu_voice_full import BaiduVoiceFull  # ç»å¯¹å¯¼å…¥
    except ImportError:
        from baidu_voice_full import BaiduVoiceFull  # åŒçº§ç›®å½•å¯¼å…¥
    BAIDU_AVAILABLE = True
except ImportError:
    BAIDU_AVAILABLE = False

# å¯¼å…¥æœ¬åœ°å½•éŸ³
try:
    import speech_recognition as sr
    import pyaudio
    LOCAL_AVAILABLE = True
except ImportError:
    LOCAL_AVAILABLE = False

class VoiceRecognizer:
    """æœ€ç»ˆç‰ˆè¯­éŸ³è¯†åˆ«å™¨ - ä½¿ç”¨ç™¾åº¦äº‘"""
    
    def __init__(self):
        print("=" * 60)
        print("ğŸ¤ è¯­éŸ³è¯†åˆ«å™¨åˆå§‹åŒ–")
        
        # åˆå§‹åŒ–ç™¾åº¦è¯­éŸ³ - å¼ºåˆ¶åˆ›å»º
        self.baidu = None
        try:
            from utils.baidu_voice_full import BaiduVoiceFull
            self.baidu = BaiduVoiceFull()
            
            print(f"ğŸ“Š ç™¾åº¦è¯­éŸ³çŠ¶æ€:")
            print(f"  available: {getattr(self.baidu, 'available', False)}")
            print(f"  APP_ID: {getattr(self.baidu, 'APP_ID', 'æœªè®¾ç½®')}")
            
            if hasattr(self.baidu, 'available') and self.baidu.available:
                print("âœ… ç™¾åº¦äº‘è¯­éŸ³è¯†åˆ«å™¨å°±ç»ª")
            else:
                print("âŒ ç™¾åº¦è¯­éŸ³è¯†åˆ«å™¨é…ç½®å¤±è´¥")
                # å°è¯•æ‰‹åŠ¨åˆ›å»º
                try:
                    from aip import AipSpeech
                    print("âš ï¸ å°è¯•æ‰‹åŠ¨åˆ›å»ºAipSpeechå®¢æˆ·ç«¯...")
                    # è¿™é‡Œå¯ä»¥æ‰‹åŠ¨åˆ›å»º
                except:
                    pass
        except ImportError as e:
            print(f"âŒ æ— æ³•å¯¼å…¥ç™¾åº¦è¯­éŸ³æ¨¡å—: {e}")
        # åˆå§‹åŒ–æœ¬åœ°å½•éŸ³
        self.recognizer = None
        self.microphone = None
        if LOCAL_AVAILABLE:
            try:
                self.recognizer = sr.Recognizer()
                # å°è¯•å¤šä¸ªéº¦å…‹é£è®¾å¤‡
                mic_indices = [1, 10, 5, 0]  # ä½ çš„è®¾å¤‡ç´¢å¼•
                for idx in mic_indices:
                    try:
                        self.microphone = sr.Microphone(device_index=idx)
                        print(f"âœ… ä½¿ç”¨éº¦å…‹é£è®¾å¤‡ {idx}")
                        break
                    except:
                        continue
                        
                if self.microphone:
                    print("âœ… æœ¬åœ°å½•éŸ³åŠŸèƒ½å°±ç»ª")
                else:
                    print("âš ï¸ æ— æ³•æ‰¾åˆ°å¯ç”¨çš„éº¦å…‹é£")
                    
            except Exception as e:
                print(f"âš ï¸ æœ¬åœ°å½•éŸ³åˆå§‹åŒ–å¤±è´¥: {e}")
        
        print("=" * 60)
        
        # ä½¿ç”¨ç»Ÿè®¡
        self.usage_count = 0
        self.last_used = None
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–"""
        if self.baidu and hasattr(self.baidu, 'available') and self.baidu.available:
            return True, "âœ… ç™¾åº¦äº‘è¯­éŸ³è¯†åˆ«å°±ç»ªï¼ˆ5ä¸‡æ¬¡å…è´¹é¢åº¦ï¼‰"
        elif self.recognizer and self.microphone:
            return True, "âœ… æœ¬åœ°å½•éŸ³å°±ç»ªï¼ˆéœ€è¦é…ç½®ç™¾åº¦APIï¼‰"
        else:
            return False, "âŒ è¯­éŸ³åŠŸèƒ½éœ€è¦å®‰è£…ä¾èµ–"
    
    def record_audio(self, duration=8):
        """å½•åˆ¶éŸ³é¢‘"""
        if not self.recognizer or not self.microphone:
            return False, "å½•éŸ³åŠŸèƒ½ä¸å¯ç”¨"
        
        try:
            with self.microphone as source:
                print(f"ğŸ¤ å¼€å§‹å½•éŸ³: {duration}ç§’")
                
                # è°ƒæ•´ç¯å¢ƒå™ªéŸ³
                self.recognizer.adjust_for_ambient_noise(source, duration=1.0)
                
                print("ğŸ”Š è¯·å¼€å§‹è¯´è¯...")
                
                # å¼€å§‹å½•éŸ³
                audio = self.recognizer.listen(
                    source,
                    timeout=duration + 5,
                    phrase_time_limit=duration
                )
                
                # âš ï¸ å…³é”®ä¿®å¤ï¼šä¿å­˜å½•éŸ³æ•°æ®åˆ°å®ä¾‹å˜é‡
                self.recording_data = audio
                print(f"âœ… å½•éŸ³å®Œæˆï¼Œæ•°æ®å·²ä¿å­˜åˆ° self.recording_data")
                
                # è¿”å›æˆåŠŸå’Œå½•éŸ³å¯¹è±¡
                return True, audio  # è¿”å› audio å¯¹è±¡ç»™è°ƒç”¨è€…
                
        except Exception as e:
            print(f"âŒ å½•éŸ³å¤±è´¥: {str(e)}")
            return False, f"å½•éŸ³å¤±è´¥: {str(e)}"
    
    def recognize(self, audio_data):
        """è¯†åˆ«è¯­éŸ³ - ä½¿ç”¨ç™¾åº¦äº‘"""
        if not self.baidu or not self.baidu.available:
            return False, "ç™¾åº¦è¯­éŸ³è¯†åˆ«æœªé…ç½®"
        
        try:
            # è®°å½•ä½¿ç”¨
            self.usage_count += 1
            self.last_used = datetime.now()
            print(f"ğŸ“Š ç¬¬ {self.usage_count} æ¬¡è¯†åˆ«è°ƒç”¨")
            
            # è°ƒç”¨ç™¾åº¦è¯†åˆ«
            success, result = self.baidu.save_and_recognize(audio_data)
            
            return success, result
            
        except Exception as e:
            return False, f"è¯†åˆ«å¤±è´¥: {str(e)}"
    
    def record_and_recognize(self, duration=8):
        """å½•éŸ³å¹¶è¯†åˆ«"""
        print(f"\n{'='*60}")
        print(f"å¼€å§‹è¯­éŸ³è¯†åˆ«æµç¨‹ (æ—¶é•¿: {duration}ç§’)")
        
        # 1. å½•éŸ³
        success, audio = self.record_audio(duration)
        if not success:
            return False, audio
        
        # 2. è¯†åˆ«
        return self.recognize(audio)
    
    def get_usage_info(self):
        """è·å–ä½¿ç”¨ä¿¡æ¯"""
        return {
            'total_calls': self.usage_count,
            'last_used': self.last_used.strftime('%Y-%m-%d %H:%M:%S') if self.last_used else 'ä»æœªä½¿ç”¨',
            'baidu_available': self.baidu and self.baidu.available,
            'microphone_available': self.microphone is not None
        }
    def transcribe_audio(self):
        """è½¬å½•éŸ³é¢‘ - é€‚é…app.pyçš„è°ƒç”¨"""
        try:
            # å¦‚æœæœ‰å½•éŸ³æ•°æ®ï¼Œå°±è°ƒç”¨ç™¾åº¦è¯†åˆ«
            if hasattr(self, 'recording_data') and self.recording_data:
                print("ğŸ” å¼€å§‹è½¬å½•éŸ³é¢‘...")
                success, result = self.recognize(self.recording_data)
                return success, result
            else:
                return False, "æ²¡æœ‰å½•éŸ³æ•°æ®"
                
        except Exception as e:
            return False, f"è½¬å½•å¤±è´¥: {str(e)}"
    
    def save_audio_to_file(self, audio_data, filename=None):
        """ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶"""
        import wave
        from datetime import datetime
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"recording_{timestamp}.wav"
        
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs("data/recordings", exist_ok=True)
            
            # ä¿å­˜æ–‡ä»¶
            if hasattr(audio_data, 'get_wav_data'):
                wav_data = audio_data.get_wav_data()
            else:
                wav_data = audio_data
                
            with open(f"data/recordings/{filename}", "wb") as f:
                f.write(wav_data)
            
            return f"data/recordings/{filename}"
        except Exception as e:
            print(f"ä¿å­˜éŸ³é¢‘å¤±è´¥: {e}")
            return None
    
    def get_audio_duration(self, audio_data):
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            import wave
            import tempfile
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
                if hasattr(audio_data, 'get_wav_data'):
                    tmp.write(audio_data.get_wav_data())
                else:
                    tmp.write(audio_data)
                tmp_path = tmp.name
            
            # è¯»å–æ—¶é•¿
            with wave.open(tmp_path, 'rb') as wav_file:
                frames = wav_file.getnframes()
                rate = wav_file.getframerate()
                duration = frames / float(rate)
            
            os.unlink(tmp_path)
            return duration
            
        except Exception as e:
            print(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 0
    def transcribe_audio(self):
        """è½¬å½•éŸ³é¢‘ - ä¼˜åŒ–è¯†åˆ«ç‰ˆ"""
        if self.recording_data is None:
            return False, "æ²¡æœ‰å½•éŸ³æ•°æ®"
        
        print("ğŸ” å¼€å§‹è½¬å½•éŸ³é¢‘...")
        
        try:
            from aip import AipSpeech
            
            # ä½ çš„APIå¯†é’¥
            APP_ID = '121914868'
            API_KEY = 'Sy4b9H4mVyl5LtYEXTsZQNqG'
            SECRET_KEY = '2l1JhXNKVnjJ1Ui3HcntaVvVrcYME9PI'
            
            client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)
            
            # è·å–å½•éŸ³æ•°æ®
            wav_data = self.recording_data.get_wav_data()
            print(f"ğŸ“Š éŸ³é¢‘æ•°æ®: {len(wav_data)} å­—èŠ‚")
            
            # ä¿å­˜å½•éŸ³ç”¨äºåˆ†æ
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            debug_file = f"debug_{timestamp}.wav"
            with open(debug_file, 'wb') as f:
                f.write(wav_data)
            print(f"ğŸ’¾ å½•éŸ³å·²ä¿å­˜: {debug_file}")
            
            # âš ï¸ å…³é”®ä¼˜åŒ–ï¼šå°è¯•ä¸åŒçš„è¯†åˆ«å‚æ•°
            recognition_results = []
            
            # å‚æ•°ç»„åˆ
            param_sets = [
                {'dev_pid': 1537, 'desc': 'æ™®é€šè¯æœç´¢æ¨¡å‹'},  # é»˜è®¤
                {'dev_pid': 1536, 'desc': 'æ™®é€šè¯è¾“å…¥æ³•æ¨¡å‹'},
                {'dev_pid': 1737, 'desc': 'è‹±è¯­'},  # å¯èƒ½æ›´é€‚åˆæ•°å­—
                {'dev_pid': 1637, 'desc': 'ç²¤è¯­'},
            ]
            
            for params in param_sets:
                try:
                    print(f"å°è¯• {params['desc']}...")
                    result = client.asr(wav_data, 'wav', 16000, {
                        'dev_pid': params['dev_pid'],
                        'cuid': f'travel_planner_{timestamp}',
                    })
                    
                    if result.get('err_no') == 0:
                        if result.get('result') and result['result'][0]:
                            text = result['result'][0].strip()
                            if text:
                                recognition_results.append({
                                    'text': text,
                                    'model': params['desc'],
                                    'confidence': self._estimate_confidence(text)
                                })
                                print(f"  âœ… {params['desc']}: {text}")
                except Exception as e:
                    print(f"  âš ï¸ {params['desc']}å¤±è´¥: {e}")
            
            # é€‰æ‹©æœ€ä½³ç»“æœ
            if recognition_results:
                # æŒ‰ç½®ä¿¡åº¦æ’åº
                recognition_results.sort(key=lambda x: x['confidence'], reverse=True)
                best_result = recognition_results[0]
                
                print(f"ğŸ¯ æœ€ä½³è¯†åˆ«ç»“æœ:")
                print(f"  æ–‡æœ¬: {best_result['text']}")
                print(f"  æ¨¡å‹: {best_result['model']}")
                print(f"  ç½®ä¿¡åº¦: {best_result['confidence']:.1%}")
                
                return True, best_result['text']
            else:
                print("âš ï¸ æ‰€æœ‰æ¨¡å‹éƒ½è¿”å›ç©ºç»“æœ")
                # ä½¿ç”¨é»˜è®¤æ¨¡å‹å†è¯•ä¸€æ¬¡
                result = client.asr(wav_data, 'wav', 16000, {'dev_pid': 1537})
                if result.get('err_no') == 0 and result.get('result'):
                    text = result['result'][0]
                    if text:
                        return True, text
                
                return False, "è¯†åˆ«å¤±è´¥"
                
        except Exception as e:
            print(f"âŒ è½¬å½•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False, f"è½¬å½•å¤±è´¥: {str(e)}"

    def _estimate_confidence(self, text):
        """ä¼°è®¡è¯†åˆ«ç½®ä¿¡åº¦ï¼ˆç®€å•ç‰ˆï¼‰"""
        # ç®€å•çš„ç½®ä¿¡åº¦ä¼°è®¡
        confidence = 0.5  # åŸºç¡€ç½®ä¿¡åº¦
        
        # æ—…è¡Œç›¸å…³å…³é”®è¯åŠ åˆ†
        travel_keywords = ['åŒ—äº¬', 'ä¸Šæµ·', 'æ—…æ¸¸', 'æ—…è¡Œ', 'å¤©', 'äºº', 'é¢„ç®—', 'ç»æµ', 'èˆ’é€‚', 'è±ªå']
        for keyword in travel_keywords:
            if keyword in text:
                confidence += 0.1
        
        # æ•°å­—åŠ åˆ†ï¼ˆå¦‚æœæ˜¯æ•°å­—çš„è¯ï¼‰
        if any(char.isdigit() for char in text):
            confidence += 0.2
        
        # ç¡®ä¿åœ¨0-1èŒƒå›´å†…
        return min(1.0, max(0.0, confidence))