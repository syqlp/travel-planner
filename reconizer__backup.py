# utils/voice_recognizer_final_baidu.py

import os
import time
import wave
import pyaudio
from datetime import datetime
import streamlit as st

class VoiceRecognizer:
    """ä¿®å¤ç‰ˆè¯­éŸ³è¯†åˆ«å™¨ - ä½¿ç”¨ç›´æ¥å½•éŸ³"""
    
    def __init__(self):
        print("ğŸ¤ åˆå§‹åŒ–ç›´æ¥å½•éŸ³è¯†åˆ«å™¨")
        
        # ç™¾åº¦APIå®¢æˆ·ç«¯
        try:
            from aip import AipSpeech
            self.client = AipSpeech(
                '121914868',
                'Sy4b9H4mVyl5LtYEXTsZQNqG',
                '2l1JhXNKVnjJ1Ui3HcntaVvVrcYME9PI'
            )
            self.api_available = True
        except Exception as e:
            print(f"âŒ ç™¾åº¦APIåˆå§‹åŒ–å¤±è´¥: {e}")
            self.api_available = False
            self.client = None
        
        # PyAudio
        try:
            self.p = pyaudio.PyAudio()
            self.pyaudio_available = True
            
            # é€‰æ‹©éº¦å…‹é£è®¾å¤‡ï¼ˆä½¿ç”¨ä½ çš„è®¾å¤‡ç´¢å¼•1ï¼‰
            self.device_index = 1  # ä½ çš„éº¦å…‹é£é˜µåˆ—è®¾å¤‡
            
        except Exception as e:
            print(f"âŒ PyAudioåˆå§‹åŒ–å¤±è´¥: {e}")
            self.p = None
            self.pyaudio_available = False
        
        # ä¿ç•™speech_recognitionä½œä¸ºå¤‡é€‰
        try:
            import speech_recognition as sr
            self.sr = sr
            self.sr_available = True
        except:
            self.sr_available = False
        
        # å½•éŸ³æ•°æ®
        self.audio_bytes = None
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–"""
        if self.api_available and self.pyaudio_available:
            return True, "âœ… ç›´æ¥å½•éŸ³åŠŸèƒ½å°±ç»ª"
        elif self.api_available and self.sr_available:
            return True, "âœ… å¤‡ç”¨å½•éŸ³åŠŸèƒ½å°±ç»ª"
        else:
            return False, "âŒ è¯­éŸ³åŠŸèƒ½éœ€è¦å®‰è£…ä¾èµ–"
    
    def record_audio(self, duration=8):
        """å½•åˆ¶éŸ³é¢‘ - ä½¿ç”¨ç›´æ¥å½•éŸ³"""
        if not self.pyaudio_available:
            return False, "ç›´æ¥å½•éŸ³åŠŸèƒ½ä¸å¯ç”¨"
        
        try:
            # å½•éŸ³å‚æ•°ï¼ˆä¸¥æ ¼æŒ‰ç…§ç™¾åº¦è¦æ±‚ï¼‰
            CHUNK = 1024
            FORMAT = pyaudio.paInt16      # 16ä½
            CHANNELS = 1                  # å•å£°é“
            RATE = 16000                  # 16kHz
            RECORD_SECONDS = duration
            
            print(f"ğŸ¤ å¼€å§‹ç›´æ¥å½•éŸ³: {duration}ç§’")
            print(f"ğŸ“Š å‚æ•°: {RATE}Hz, {CHANNELS}å£°é“, {FORMAT}æ ¼å¼")
            
            # æ‰“å¼€éŸ³é¢‘æµ
            stream = self.p.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                input_device_index=self.device_index,
                frames_per_buffer=CHUNK
            )
            
            # å½•éŸ³
            frames = []
            for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):
                data = stream.read(CHUNK)
                frames.append(data)
            
            # åœæ­¢æµ
            stream.stop_stream()
            stream.close()
            
            # åˆå¹¶æ•°æ®
            self.audio_bytes = b''.join(frames)
            print(f"âœ… å½•éŸ³å®Œæˆ: {len(self.audio_bytes)} å­—èŠ‚")
            
            # ä¿å­˜å½•éŸ³æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"data/recordings/app_{timestamp}.wav"
            os.makedirs("data/recordings", exist_ok=True)
            
            wf = wave.open(filename, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.p.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(self.audio_bytes)
            wf.close()
            
            print(f"ğŸ’¾ å·²ä¿å­˜: {filename}")
            
            return True, "å½•éŸ³æˆåŠŸ"
            
        except Exception as e:
            print(f"âŒ ç›´æ¥å½•éŸ³å¤±è´¥: {e}")
            # å°è¯•å¤‡ç”¨æ–¹æ³•
            return self._record_audio_fallback(duration)
    
    def _record_audio_fallback(self, duration):
        """å¤‡ç”¨å½•éŸ³æ–¹æ³•ï¼ˆä½¿ç”¨speech_recognitionï¼‰"""
        if not self.sr_available:
            return False, "æ²¡æœ‰å¯ç”¨çš„å½•éŸ³æ–¹æ³•"
        
        try:
            r = self.sr.Recognizer()
            
            with self.sr.Microphone(device_index=self.device_index) as source:
                print("ğŸ”„ ä½¿ç”¨å¤‡ç”¨å½•éŸ³æ–¹æ³•...")
                r.adjust_for_ambient_noise(source, duration=1.0)
                
                audio = r.listen(
                    source,
                    timeout=duration + 5,
                    phrase_time_limit=duration
                )
                
                # è½¬æ¢ä¸ºbytes
                self.audio_bytes = audio.get_wav_data()
                print(f"âœ… å¤‡ç”¨å½•éŸ³å®Œæˆ: {len(self.audio_bytes)} å­—èŠ‚")
                
                return True, "å½•éŸ³æˆåŠŸ"
                
        except Exception as e:
            print(f"âŒ å¤‡ç”¨å½•éŸ³å¤±è´¥: {e}")
            return False, f"å½•éŸ³å¤±è´¥: {str(e)}"
    
    def transcribe_audio(self):
        """è½¬å½•éŸ³é¢‘"""
        if not self.audio_bytes:
            return False, "æ²¡æœ‰å½•éŸ³æ•°æ®"
        
        if not self.client:
            return False, "ç™¾åº¦APIä¸å¯ç”¨"
        
        print("ğŸ” å¼€å§‹è½¬å½•éŸ³é¢‘...")
        
        try:
            # ç›´æ¥è°ƒç”¨ç™¾åº¦API
            result = self.client.asr(
                self.audio_bytes,
                'wav',
                16000,
                {
                    'dev_pid': 1537,  # æ™®é€šè¯
                    'cuid': f'travel_planner_{int(time.time())}',
                }
            )
            
            print(f"ğŸ“‹ APIè¿”å›: {result}")
            
            if result.get('err_no') == 0:
                text = result.get('result', [''])[0]
                if text and text.strip():
                    print(f"âœ… è¯†åˆ«æˆåŠŸ: '{text}'")
                    return True, text.strip()
                else:
                    print("âš ï¸ è¯†åˆ«ç»“æœä¸ºç©º")
                    return False, "è¯†åˆ«ç»“æœä¸ºç©º"
            else:
                error_msg = result.get('err_msg', 'æœªçŸ¥é”™è¯¯')
                print(f"âŒ APIé”™è¯¯: {error_msg}")
                return False, error_msg
                
        except Exception as e:
            print(f"âŒ è½¬å½•å¤±è´¥: {e}")
            return False, f"è½¬å½•å¤±è´¥: {str(e)}"
    
    def parse_travel_demand(self, text):
        """è§£ææ—…è¡Œéœ€æ±‚"""
        import re
        
        demand = {
            'destination': None,
            'days': 3,
            'people': 2,
            'budget': 'èˆ’é€‚å‹(äººå‡300-600å…ƒ/å¤©)',
            'styles': []
        }
        
        # ç›®çš„åœ°
        destinations = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'æˆéƒ½', 'è¥¿å®‰', 'å—äº¬']
        for dest in destinations:
            if dest in text:
                demand['destination'] = dest
                break
        
        # å¤©æ•°
        day_match = re.search(r'(\d+)\s*å¤©', text)
        if day_match:
            try:
                days = int(day_match.group(1))
                if 1 <= days <= 30:
                    demand['days'] = days
            except:
                pass
        
        # äººæ•°
        people_match = re.search(r'(\d+)\s*äºº', text)
        if people_match:
            try:
                people = int(people_match.group(1))
                if 1 <= people <= 20:
                    demand['people'] = people
            except:
                pass
        
        # é¢„ç®—
        if 'ç»æµ' in text or 'ä¾¿å®œ' in text:
            demand['budget'] = 'ç»æµå‹(äººå‡300å…ƒ/å¤©ä»¥ä¸‹)'
        elif 'è±ªå' in text or 'å¥¢ä¾ˆ' in text:
            demand['budget'] = 'è±ªåå‹(äººå‡600å…ƒ/å¤©ä»¥ä¸Š)'
        
        # é£æ ¼
        style_keywords = {
            'ä¼‘é—²': 'ğŸ–ï¸ ä¼‘é—²æ”¾æ¾',
            'æ–‡åŒ–': 'ğŸ¨ æ–‡åŒ–æ¢ç´¢', 
            'ç¾é£Ÿ': 'ğŸœ ç¾é£Ÿä¹‹æ—…',
            'è‡ªç„¶': 'ğŸï¸ è‡ªç„¶é£å…‰',
            'å†’é™©': 'ğŸ¢ å†’é™©åˆºæ¿€',
            'äº²å­': 'ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ å®¶åº­äº²å­',
            'æµªæ¼«': 'ğŸ’– æƒ…ä¾£æµªæ¼«',
            'æ‘„å½±': 'ğŸ“¸ æ‘„å½±æ‰“å¡'
        }
        
        for keyword, style in style_keywords.items():
            if keyword in text:
                demand['styles'].append(style)
        
        if not demand['styles']:
            demand['styles'] = ['ğŸ–ï¸ ä¼‘é—²æ”¾æ¾', 'ğŸï¸ è‡ªç„¶é£å…‰']
        
        return demand
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'p') and self.p:
            self.p.terminate()
            print("âœ… å·²æ¸…ç†PyAudioèµ„æº")

# ç®€å•æµ‹è¯•
def test():
    vr = VoiceRecognizer()
    
    success, msg = vr.check_dependencies()
    print(f"ä¾èµ–æ£€æŸ¥: {msg}")
    
    if "å°±ç»ª" in msg:
        print("\nğŸ¤ æµ‹è¯•å½•éŸ³ï¼ˆ3ç§’ï¼‰...")
        success, msg = vr.record_audio(3)
        
        if success:
            print("\nğŸ” æµ‹è¯•è¯†åˆ«...")
            success, text = vr.transcribe_audio()
            
            if success:
                print(f"\nâœ… è¯†åˆ«ç»“æœ: '{text}'")
                
                parsed = vr.parse_travel_demand(text)
                print(f"\nğŸ¯ è§£æç»“æœ:")
                print(f"  ç›®çš„åœ°: {parsed['destination']}")
                print(f"  å¤©æ•°: {parsed['days']}")
                print(f"  äººæ•°: {parsed['people']}")
                print(f"  é¢„ç®—: {parsed['budget']}")
                print(f"  é£æ ¼: {parsed['styles']}")
        
        vr.cleanup()

if __name__ == "__main__":
    test()